{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1dZKPU2ZLTGLN6RnbTlnqyucJ6eIzi645",
      "authorship_tag": "ABX9TyNzERzJnxoCAQ/V9vl6NGgB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kirankumarpetlu/CropYieldPrediction-MLR/blob/main/NIDSmodel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3dxnOjPA37V",
        "outputId": "a2bd3e08-42d8-42e4-9297-e2b44128f5a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scapy\n",
            "  Downloading scapy-2.6.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Downloading scapy-2.6.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scapy\n",
            "Successfully installed scapy-2.6.1\n"
          ]
        }
      ],
      "source": [
        "!pip install scapy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Conv1D, Flatten, LSTM, SimpleRNN\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from scapy.all import sniff, IP, TCP, UDP"
      ],
      "metadata": {
        "id": "RXbZ7LvkBBnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QixhujoVBMkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "data_path = {\n",
        "    \"/content/Monday-WorkingHours.pcap_ISCX.csv\": \"Normal\",\n",
        "    \"/content/Tuesday-WorkingHours.pcap_ISCX.csv\": \"Brute Force Attack\",\n",
        "    \"/content/Wednesday-WorkingHours.pcap_ISCX.csv\": \"DoS and Heartbleed Attacks\",\n",
        "    \"/content/Thursday-WorkingHours-MorningWebAttacks.pcap_ISCX.csv\": \"Web-based Attacks\",\n",
        "    \"/content/Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\": \"Infiltration Attacks\",\n",
        "    \"/content/Friday-WorkingHours-Morning.pcap_ISCX.csv\": \"\",\n",
        "    \"/content/Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\": \"Port Scanning Attack\",\n",
        "    \"/content/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\": \"\"\n",
        "}\n",
        "file_attack_mapping = {\n",
        "    file_path: attack_type\n",
        "    for file_path, attack_type in data_path.items()\n",
        "}\n",
        "\n",
        "def load_data():\n",
        "    df_list = []\n",
        "    for file, attack_type in file_attack_mapping.items():\n",
        "        if os.path.exists(file):\n",
        "            temp_df = pd.read_csv(file, low_memory=False)\n",
        "            temp_df['Attack_Type'] = attack_type\n",
        "            df_list.append(temp_df)\n",
        "        else:\n",
        "            print(f\"Warning: File not found: {file}. Skipping...\")\n",
        "    df = pd.concat(df_list, ignore_index=True)\n",
        "    return df\n",
        "\n",
        "def preprocess_data(df):\n",
        "    df = df.drop(columns=['Flow ID', 'Source IP', 'Destination IP', 'Timestamp'], errors='ignore')\n",
        "\n",
        "    # Replace infinite values with NaN\n",
        "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
        "\n",
        "    # Drop rows with NaN values\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    df['Label'] = df['Attack_Type'].apply(lambda x: 1 if x != \"Normal\" else 0)\n",
        "\n",
        "    for column in df.select_dtypes(include=['object']).columns:\n",
        "        if column not in ['Label', 'Attack_Type']:\n",
        "            label_encoder = LabelEncoder()\n",
        "            df[column] = label_encoder.fit_transform(df[column])\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(df.drop(columns=['Label', 'Attack_Type']))\n",
        "    y = df['Label'].values\n",
        "    return X, y\n",
        "\n",
        "df = load_data()\n",
        "X, y = preprocess_data(df)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMyRl5WaNeSw",
        "outputId": "8e9bcb5e-e217-4730-8c2f-4d4ec55ea992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: File not found: /content/Wednesday-WorkingHours.pcap_ISCX.csv. Skipping...\n",
            "Warning: File not found: /content/Thursday-WorkingHours-MorningWebAttacks.pcap_ISCX.csv. Skipping...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "from tensorflow.keras.layers import MaxPooling1D, Dropout # Import Dropout\n",
        "\n",
        "def build_cnn():\n",
        "    model = Sequential([\n",
        "        Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "90CeapqoC0cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM Model\n",
        "def build_lstm():\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
        "        LSTM(32),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "MfjC1lNMCzws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RNN Model\n",
        "def build_rnn():\n",
        "    model = Sequential([\n",
        "        SimpleRNN(64, return_sequences=True, input_shape=(X_train.shape[1], 1)),\n",
        "        SimpleRNN(32),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "metadata": {
        "id": "lk-QX0I1DNj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_save_model(model, name):\n",
        "    history = model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "    model.save(f\"/content/nids_{name}.h5\")\n",
        "    print(f\"✅ Model {name} saved!\")\n",
        "    return max(history.history['val_accuracy'])\n",
        "\n",
        "cnn_model = build_cnn()\n",
        "cnn_acc = train_and_save_model(cnn_model, \"cnn\")\n",
        "\n",
        "lstm_model = build_lstm()\n",
        "lstm_acc = train_and_save_model(lstm_model, \"lstm\")\n",
        "\n",
        "rnn_model = build_rnn()\n",
        "rnn_acc = train_and_save_model(rnn_model, \"rnn\")\n",
        "\n",
        "# Select the Best Model\n",
        "best_model_name = max((\"cnn\", cnn_acc), (\"lstm\", lstm_acc), (\"rnn\", rnn_acc), key=lambda x: x[1])[0]\n",
        "best_model = tf.keras.models.load_model(f\"/content/nids_{best_model_name}.h5\")\n",
        "print(f\"✅ Loaded best model: {best_model_name}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRH9P7xhDcDl",
        "outputId": "d35d8e75-75d9-43c9-a1fe-5b53cec26a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 4ms/step - accuracy: 0.8309 - loss: 0.4010 - val_accuracy: 0.8388 - val_loss: 0.3740\n",
            "Epoch 2/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.8370 - loss: 0.3798 - val_accuracy: 0.8417 - val_loss: 0.3680\n",
            "Epoch 3/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 3ms/step - accuracy: 0.8422 - loss: 0.3703 - val_accuracy: 0.8473 - val_loss: 0.3617\n",
            "Epoch 4/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - accuracy: 0.8417 - loss: 0.3688 - val_accuracy: 0.8490 - val_loss: 0.3569\n",
            "Epoch 5/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.8423 - loss: 0.3660 - val_accuracy: 0.8496 - val_loss: 0.3548\n",
            "Epoch 6/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.8446 - loss: 0.3616 - val_accuracy: 0.8506 - val_loss: 0.3547\n",
            "Epoch 7/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 3ms/step - accuracy: 0.8444 - loss: 0.3625 - val_accuracy: 0.8510 - val_loss: 0.3545\n",
            "Epoch 8/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 3ms/step - accuracy: 0.8449 - loss: 0.3618 - val_accuracy: 0.8503 - val_loss: 0.3518\n",
            "Epoch 9/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 3ms/step - accuracy: 0.8457 - loss: 0.3588 - val_accuracy: 0.8509 - val_loss: 0.3505\n",
            "Epoch 10/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 3ms/step - accuracy: 0.8462 - loss: 0.3572 - val_accuracy: 0.8516 - val_loss: 0.3478\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Model cnn saved!\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 13ms/step - accuracy: 0.8297 - loss: 0.4168 - val_accuracy: 0.8339 - val_loss: 0.3816\n",
            "Epoch 2/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 12ms/step - accuracy: 0.8353 - loss: 0.3795 - val_accuracy: 0.8433 - val_loss: 0.3700\n",
            "Epoch 3/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 13ms/step - accuracy: 0.8414 - loss: 0.3699 - val_accuracy: 0.8463 - val_loss: 0.3620\n",
            "Epoch 4/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 13ms/step - accuracy: 0.8440 - loss: 0.3652 - val_accuracy: 0.8416 - val_loss: 0.3646\n",
            "Epoch 5/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13ms/step - accuracy: 0.8442 - loss: 0.3617 - val_accuracy: 0.8492 - val_loss: 0.3542\n",
            "Epoch 6/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m134s\u001b[0m 12ms/step - accuracy: 0.8476 - loss: 0.3567 - val_accuracy: 0.8495 - val_loss: 0.3537\n",
            "Epoch 7/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 13ms/step - accuracy: 0.8474 - loss: 0.3555 - val_accuracy: 0.8502 - val_loss: 0.3515\n",
            "Epoch 8/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13ms/step - accuracy: 0.8465 - loss: 0.3553 - val_accuracy: 0.8470 - val_loss: 0.3527\n",
            "Epoch 9/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 13ms/step - accuracy: 0.8498 - loss: 0.3502 - val_accuracy: 0.8523 - val_loss: 0.3482\n",
            "Epoch 10/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 13ms/step - accuracy: 0.8503 - loss: 0.3490 - val_accuracy: 0.8513 - val_loss: 0.3480\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model lstm saved!\n",
            "Epoch 1/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m149s\u001b[0m 14ms/step - accuracy: 0.8290 - loss: 0.4258 - val_accuracy: 0.8342 - val_loss: 0.4236\n",
            "Epoch 2/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m188s\u001b[0m 13ms/step - accuracy: 0.8317 - loss: 0.4205 - val_accuracy: 0.8313 - val_loss: 0.4250\n",
            "Epoch 3/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 13ms/step - accuracy: 0.8309 - loss: 0.4279 - val_accuracy: 0.8351 - val_loss: 0.4257\n",
            "Epoch 4/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 13ms/step - accuracy: 0.8316 - loss: 0.4250 - val_accuracy: 0.8341 - val_loss: 0.4251\n",
            "Epoch 5/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 14ms/step - accuracy: 0.8328 - loss: 0.4275 - val_accuracy: 0.8348 - val_loss: 0.4231\n",
            "Epoch 6/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 13ms/step - accuracy: 0.8337 - loss: 0.4255 - val_accuracy: 0.8329 - val_loss: 0.4267\n",
            "Epoch 7/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 13ms/step - accuracy: 0.8323 - loss: 0.4231 - val_accuracy: 0.8310 - val_loss: 0.4287\n",
            "Epoch 8/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 13ms/step - accuracy: 0.8333 - loss: 0.4229 - val_accuracy: 0.8342 - val_loss: 0.4146\n",
            "Epoch 9/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 14ms/step - accuracy: 0.8317 - loss: 0.4247 - val_accuracy: 0.8343 - val_loss: 0.4208\n",
            "Epoch 10/10\n",
            "\u001b[1m10332/10332\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m133s\u001b[0m 13ms/step - accuracy: 0.8332 - loss: 0.4242 - val_accuracy: 0.8341 - val_loss: 0.4179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Model rnn saved!\n",
            "✅ Loaded best model: lstm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def live_packet_sniffing(model):\n",
        "    def process_packet(packet):\n",
        "        features = []\n",
        "        if packet.haslayer(IP):\n",
        "            features.append(packet[IP].len)\n",
        "            features.append(packet[IP].ttl)\n",
        "            features.append(packet[IP].proto)\n",
        "        else:\n",
        "            features.extend([0, 0, 0])\n",
        "        if packet.haslayer(TCP) or packet.haslayer(UDP):\n",
        "            features.append(packet.sport)\n",
        "            features.append(packet.dport)\n",
        "        else:\n",
        "            features.extend([0, 0])\n",
        "        features = np.array(features).reshape(1, -1)\n",
        "        prediction = model.predict(features)\n",
        "        attack_detected = prediction[0][0] > 0.5\n",
        "        status = \"Intrusion\" if attack_detected else \"Normal\"\n",
        "        socketio.emit('update', {'status': status})\n",
        "        print(f\"Packet: {features} -> {status}\")\n",
        "    sniff(prn=process_packet, store=False)\n"
      ],
      "metadata": {
        "id": "Z1DkLccOJil9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}